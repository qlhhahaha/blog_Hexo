---
title: 论文学习：A survey of distributed optimization
date: 2023-09-10
tags: [分布式优化, 多智能体控制]
categories: 科研只为把业毕
---



一些参考：

[Distributed Optimization Algorithms](https://forshining.github.io/posts/2022/07/blog-post-DistriOptim/)



# A survey of distributed optimization, 2019, Annual Reviews in Control

### 一、introduction

1. **分布式优化**
	$$
	\min_{x\in\mathbb{R}^n}\sum_{i=1}^Nf_i(x),
	$$
	

### 二、离散时间分布式优化算法

1. **递减步长（diminishing step-sizes）**

	**DGD: Distributed Gradient Descent**
	$$
	x_i(k+1)=\sum_{j=1}^Nw_{ij}(k)x_j(k)-\alpha(k)s_i(k),
	$$
	其中$w_{ij}(k)$是边的权重，$s_i(k)$是局部函数$f_i(x)$的（次）梯度，$\alpha(k)>0$是递减的步长，其满足：
	$$
	\sum_{k=0}^\infty\alpha\left(k\right)=\infty,\sum_{k=0}^\infty\alpha^2(k)<\infty,
	$$

	$$
	\alpha\left(k\right)\leq\alpha\left(s\right)\mathrm{~for~all~}k>s\geq0.
	$$

	DGD算法本质上是将优化过程分成了两部分：一部分是consensus,即利用Weight matrix将连通节点的信息做一个沟通；另一部分就是传统的梯度下降，这里的梯度下降是针对每一个local节点。而DGD有一个显著的缺点：如果DGD当中的步长选择常数的话，那么会得到inexact convergence；而如果选择逐渐趋于零的步长(diminishing step size)，那么虽然可以得到exact convergence, 但是会造成较慢的收敛速度，这在实际应用当中是一个棘手的问题。

	```matlab
	% DGD仿真
	
	num_nodes = 5;  % 节点数量
	
	% 有向图
	adjacency_matrix_dir = [ 1  0 -1  0  0;
	                        -1  2  0  0 -1;
	                        -1 -1  2  0  0;
	                         0  0 -1  1  0;
	                         0  0  0 -1  1];  
	
	% 无向图
	adjacency_matrix_undir = [ 2 -1 -1  0  0;
	                          -1  2  0  0 -1;
	                          -1  0  2 -1  0;
	                           0  0 -1  2 -1;
	                           0 -1  0 -1  2];  
	
	
	% 初始化节点参数和本地梯度
	%node_params = rand(num_nodes, 1);  % 初始参数
	node_params = [0.1 0.2 0.3 0.4 0.5]';
	local_gradients = zeros(num_nodes, 1);
	
	% 设置全局目标函数（示例中为简单的平方和）
	global_objective = @(x) sum(x.^2);
	
	num_iterations = 1000;
	learning_rate = 0.01;
	
	% 创建用于存储可视化数据的数组
	param_history = zeros(num_iterations, num_nodes);
	
	
	for iteration = 1:num_iterations
	    for node = 1:num_nodes
	        local_gradients(node) = 2 * node_params(node);
	        
	        % 与邻居节点共享梯度信息并更新参数
	        for neighbor = 1:num_nodes
	            if adjacency_matrix_dir(node, neighbor) == -1
	                node_params(node) = node_params(node) - learning_rate * (node_params(node) - node_params(neighbor));
	            end
	        end
	        
	        % 存储参数历史
	        param_history(iteration, :) = node_params;
	    end
	end
	
	% 输出最终的全局最优解
	global_minimizer = node_params;
	global_minimum = global_objective(global_minimizer);
	fprintf('全局最优解：');
	disp(global_minimizer);
	fprintf('全局最小值：%f\n', global_minimum);
	
	% 可视化节点参数随时间的变化
	figure;
	hold on;
	for node = 1:num_nodes
	    plot(1:num_iterations, param_history(:, node), 'LineWidth', 2, 'DisplayName', sprintf('节点 %d', node));
	end
	xlabel('迭代次数');
	ylabel('节点参数');
	title('节点参数随时间的变化');
	legend('Location', 'Best');
	grid on;
	hold off;
	
	```

	仿真结果：

	![无向图](https://s2.loli.net/2023/09/11/unY1li45ovgDGUR.png)

	无需太多解释，为无向图完全连通时，最终各节点值趋于平均值，即经典的consensus

	![有向图](https://s2.loli.net/2023/09/11/ST9zrA3w4no6muy.png)
	
	为有向图时，因为不是各节点之间都还能“均匀地”通信，所以结果也不再是全局平均
	
	

{% note warning%}

💡 PS. 只要能够收敛，各节点最终的收敛值就与目标函数无关哈（跟全局和局部目标函数都无关，全局只是局部之和而已），只与通信拓扑有关。因为从迭代过程中就可以发现，只有梯度和目标函数有关，但梯度只影响迭代速率（或者说顶多导致震荡，无法收敛到精确值），不影响收敛终值

{% endnote %}



2. **固定步长（fixed step-sizes）**

	**EXTRA: Exact first-order algorithm**

	第一步：
$$
x_i(1)=\sum_{j=1}^Nw_{ij}x_j(0)-\alpha\nabla f_i(x_i(0)),
$$

​		其中$$\alpha>0$$是固定步长
​	

​		第二步：
$$
\begin{aligned}x_i(k+2)&=x_i(k+1)+\sum_{j=1}^Nw_{ij}x_j(k+1)-\sum_{j=1}^N\tilde{w}_{ij}x_j(k)-\alpha\left(\nabla f_i(x_i(k+1))-\nabla f_i(x_i(k))\right),\mathrm{~}k=0,\mathrm{~}1,\ldots,\end{aligned}
$$
​		相较于DGD算法，EXTRA用到了前两步的梯度信息，文献表明，**EXTRA可以看作是具有误差校正项的DGD**



​		**DIGing： distributed inexact gradient method and the gradient tracking**

$$
x_i(k+1) =\sum_{j=1}^Nw_{ij}x_j(k)-\alpha y_i(k),
$$

$$
y_{i}(k+1) =\sum_{i=1}^Nw_{ij}y_j(k)+\nabla f_i(x_i(k+1))-\nabla f_i(x_i(k))
$$



​		**Distributed PI algorithm**
$$
x_i(k+1)=x_i(k)-v_i(k)-\alpha\nabla f_i(x_i(k))-\beta\sum_{j\in\mathcal{N}_i}a_{ij}(x_i(k)-x_j(k)),
$$

$$
\nu_i(k+1) =v_i(k)+\alpha\beta\sum_{j\in\mathcal{N}_i}a_{ij}(x_i(k)-x_j(k))
$$




3. **一阶梯度算法**

	**Distributed PI algorithm**
$$
\dot{x}_i(t) =\sum_{j=1}^Na_{ij}(x_j(t)-x_i(t))+\sum_{j=1}^Na_{ij}(\nu_j(t)-\nu_i(t))-\nabla f_i(x_i(t)),
$$

$$
\dot{\nu}_i(t) =\sum_{j=1}^Na_{ij}(x_i(t)-x_j(t))
$$

4. **二阶梯度算法**

	**Zero-Gradient-Sum Algorithm**
$$
\dot{x}_i(t)=\gamma\left(\nabla^2f_i(x_i(t))\right)^{-1}\sum_{j\in\mathcal{N}_i}a_{ij}(x_j(t)-x_i(t))
$$


### 四、拓展场景中的分布式优化算法

1. **有向图**

  **Distributed Push-Sum Based Algorithm（离散时间）**

  大部分现有的有向图离散时间分布式算法都是基于推和



  ​	

 2.  **时延**

 3.  **随机拓扑**

 4.  **事件触发机制**（精读！）

 5.  **有限时间收敛**

	
